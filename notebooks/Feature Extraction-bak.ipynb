{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../original/pytorch')\n",
    "from read_feats_classV5 import ASVSpoofTrainData\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to jump over to the pytorch dir to make paths work in that module\n",
    "os.chdir('../original/pytorch')\n",
    "tdata = ASVSpoofTrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = tdata[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work out which input file we're looking at\n",
    "data_fn = 'train_info.lst'\n",
    "with open(data_fn, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "data['names'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.subplots()\n",
    "_ = plt.pcolormesh(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project uses a Matlab FFT routine (in `logpow.m`) to calculate a log power spectrum with a window size of 16ms and an overlap of 8ms.  The FFT size is 1536 points to give a resulting 768 point spectrum (matching the input image size of AlexNET) but with a 16kHz sample frequency the window only contains 256 points so the remainder must be padded with zeros (I can't find a reference to this behavior).  This would have the effect of giving better frequency resolution in the FFT although with only 256 points of data it will just be a smoothed out spectrum.\n",
    "\n",
    "The matlab code applies a hamming window prior to the FFT operation, then takes the log of the squared FFT. The result is written to an h5 file.\n",
    "\n",
    "These h5 files are then read by the script `split-data-768.py` which generates a fixed size array of 768x400 by repeating the data if it is shorter than 400 points or truncating if it is longer.  The features are then normalised (subtract mean and divide by stdev) before being saved to npy format files.\n",
    "\n",
    "These npy files are then read by the code above and used as input to the network.\n",
    "\n",
    "The result plotted above shows the spectrum with some horizontal (pitch) banding at lower frequencies in the voiced sections. Higher frequencies are messy and the normalisation of the spectrum has maybe reduced the contrast.  We can se the repitition of the signal after around 300 on the x-axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction with Sidekit\n",
    "\n",
    "Now we'll try to reproduce something like this using the sidekit library but perhaps with some more sensible settings for the FFT.\n",
    "\n",
    "One issue is that Sidekit does not do zero padding on FFT spectra so we can't fully reproduce the original features.  However, I'm not sure that zero padding was done for any good reason other than to fit into the 768x400 image size.  \n",
    "\n",
    "We define a function to create a feature extractor, parameterising the frame size and shift.  Then we can compute the spectrogram for the same input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sidekit \n",
    "def make_feature_server(frame_size, shift):\n",
    " \n",
    "    sampling_frequency = 16000\n",
    "    # window size must be twice the frame size to give the right number of FFT points but since\n",
    "    # we can't zero pad, we'll be taking in more of the signal in each frame\n",
    "    window_size =  (2* frame_size+1) / sampling_frequency\n",
    "\n",
    "\n",
    "    extractor = sidekit.FeaturesExtractor(audio_filename_structure=\"../../data/ASVspoof2017/ASVspoof2017_V2_train/{}.wav\",\n",
    "                                          feature_filename_structure=\"../../data/feat/{}.h5\",\n",
    "                                          sampling_frequency=sampling_frequency,\n",
    "                                          lower_frequency=0,\n",
    "                                          higher_frequency=sampling_frequency/2,\n",
    "                                          filter_bank=\"lin\",\n",
    "                                          filter_bank_size=frame_size,\n",
    "                                          window_size=window_size,\n",
    "                                          shift=shift,\n",
    "                                          ceps_number=20,\n",
    "                                          pre_emphasis=0.97,\n",
    "                                          save_param=[\"fb\"],\n",
    "                                          keep_all_features=True)\n",
    "\n",
    "    return sidekit.FeaturesServer(features_extractor=extractor,\n",
    "                                    feature_filename_structure=\"../../data/feat/{}.h5\",\n",
    "                                    sources=None,\n",
    "                                    dataset_list=[\"fb\"],\n",
    "                                    keep_all_features=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll compute a spectrogram with the same size using a frame size of 768. This creates a very large window but with a small frame shift of 0.008s there is a huge overlap between frames. This means we get very good frequency resolution but temporally features are very blurred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = make_feature_server(768, 0.008)\n",
    "\n",
    "feat, label = fs.load('T_1000001')\n",
    "print(feat.shape)\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "_=plt.pcolormesh(feat.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison, the original features again but truncated to align with the above figure\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "_=plt.pcolormesh(spec[:,:291])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frequency resolution is actually much better in the sidekit version since we're taking more signal but the temporal blurring is very apparent.  \n",
    "\n",
    "We can get a better temporal resolution with a smaller frame size and the same shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs127 = make_feature_server(127, 0.008)\n",
    "\n",
    "feat127, label = fs127.load('T_1000001')\n",
    "print(feat127.shape)\n",
    "fig = plt.figure(figsize=(15,2))\n",
    "_=plt.pcolormesh(feat127.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the plosive at around 140 which is much more apparent here than even the original plot and very smudged in the wideband spectrogram.  \n",
    "\n",
    "\n",
    "## Â¿Por qu&eacute; no los dos?\n",
    "\n",
    "Since the goal is to get an 'image' of 768x400 for input to the CNN we could actually combine both narrow and wide band spectra into a single image to get the best of both worlds.  Keeping the 8ms window shift we can compute one spectrum of 127 points and another of 641 points and splice them together into a single 'image'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs641 = make_feature_server(641, 0.008)\n",
    "\n",
    "feat641, label = fs641.load('T_1000001')\n",
    "print(feat641.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_combined = np.concatenate((feat641, feat127[:293,:]), axis=1)\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "_=plt.pcolormesh(feat_combined.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicating the original code we can repeat the data to give an overall image size of 768x400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = feat_combined.transpose()\n",
    "size = mat.shape[1] \n",
    "mat = np.concatenate((mat,mat[:,0:400-size]), axis=1)\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "_=plt.pcolormesh(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again to compare with the original\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "ax = fig.subplots()\n",
    "_ = plt.pcolormesh(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mat, axis):\n",
    "    \"\"\"Normalise data\"\"\"\n",
    "\n",
    "    nFeatures = 768\n",
    "\n",
    "    mat = (mat - np.mean(mat,axis=axis,keepdims=True))\n",
    "    mat = np.divide(mat,np.std(mat,axis=axis,keepdims=True))\n",
    "\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "fig = plt.figure(figsize=(15,6))\n",
    "_=plt.pcolormesh(normalize(mat,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "124663ec-8908-4888-a868-5f84e1b9237d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
